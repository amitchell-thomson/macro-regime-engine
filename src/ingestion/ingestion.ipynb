{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2f733cc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Force reload of modules during development\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1352d9ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from download import download_ticker\n",
        "from database import (\n",
        "    get_connection, \n",
        "    upsert_raw_series, \n",
        "    log_ingestion_run,\n",
        "    close_connection\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "773d91df",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_universe():\n",
        "    \"\"\"Load tickers from universe.yml\"\"\"\n",
        "    universe_path = Path.cwd().parent.parent / 'configs' / 'universe.yml'\n",
        "    \n",
        "    with open(universe_path, 'r') as f:\n",
        "        universe = yaml.safe_load(f)\n",
        "    \n",
        "    # Flatten into list\n",
        "    tickers = []\n",
        "    for asset_class, ticker_list in universe.items():\n",
        "        for item in ticker_list:\n",
        "            tickers.append({\n",
        "                'ticker': item['ticker'],\n",
        "                'name': item['name'],\n",
        "                'source': item['source'],\n",
        "                'asset_class': asset_class.upper()\n",
        "            })\n",
        "    \n",
        "    return tickers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8b161812",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ingest_all(start_date='2010-01-01', ticker_filter=None, dry_run=False):\n",
        "    \"\"\"\n",
        "    Main ingestion function.\n",
        "    \n",
        "    Args:\n",
        "        start_date: Start date for historical data\n",
        "        ticker_filter: If provided, only ingest this ticker\n",
        "        dry_run: If True, download but don't store in database\n",
        "    \"\"\"\n",
        "    # Load environment\n",
        "    load_dotenv()\n",
        "    fred_api_key = os.getenv('FRED_API_KEY')\n",
        "    db_password = os.getenv('DB_PASSWORD')\n",
        "    \n",
        "    # Load universe\n",
        "    tickers = load_universe()\n",
        "    \n",
        "    if ticker_filter:\n",
        "        tickers = [t for t in tickers if t['ticker'] in ticker_filter]\n",
        "    \n",
        "    print(f\"Ingesting {len(tickers)} tickers...\")\n",
        "    \n",
        "    # Connect to database\n",
        "    conn = None if dry_run else get_connection(password=db_password)\n",
        "    \n",
        "    # Start ingestion log\n",
        "    run_id = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    if not dry_run:\n",
        "        log_ingestion_run(conn, run_id, 'running', f'Ingesting {len(tickers)} tickers')\n",
        "    \n",
        "    success_count = 0\n",
        "    fail_count = 0\n",
        "    \n",
        "    # Process each ticker\n",
        "    for ticker_info in tickers:\n",
        "        ticker = ticker_info['ticker']\n",
        "        source = ticker_info['source']\n",
        "        asset_class = ticker_info['asset_class']\n",
        "        print(f\"Processing {ticker} ({asset_class}) from {source}...\")\n",
        "        \n",
        "        # Download\n",
        "        df = download_ticker(ticker, source, fred_api_key, start_date)\n",
        "        \n",
        "        if df is not None and not df.empty:\n",
        "            if not dry_run:\n",
        "                # Store in database\n",
        "                row_count = upsert_raw_series(conn, df, asset_class)\n",
        "                print(f\"  ✓ Inserted {row_count} rows\")\n",
        "            else:\n",
        "                print(f\"  ✓ Downloaded {len(df)} rows (dry run - not stored)\")\n",
        "            \n",
        "            success_count += 1\n",
        "        else:\n",
        "            print(f\"  ✗ Failed to download\")\n",
        "            fail_count += 1\n",
        "    \n",
        "    # Finish ingestion log\n",
        "    if not dry_run:\n",
        "        log_ingestion_run(\n",
        "            conn, run_id, 'ok', \n",
        "            f'Success: {success_count}, Failed: {fail_count}'\n",
        "        )\n",
        "        close_connection(conn)\n",
        "    \n",
        "    print(f\"\\nIngestion complete! Success: {success_count}, Failed: {fail_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "99dffbf0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingesting 54 tickers...\n",
            "Processing ^GSPC (EQUITY) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing ^DJI (EQUITY) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing ^IXIC (EQUITY) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing ^RUT (EQUITY) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing EEM (EQUITY) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing ^FTSE (EQUITY) from yfinance...\n",
            "  ✓ Inserted 4029 rows\n",
            "Processing ^N225 (EQUITY) from yfinance...\n",
            "  ✓ Inserted 3902 rows\n",
            "Processing 000001.SS (EQUITY) from yfinance...\n",
            "  ✓ Inserted 3870 rows\n",
            "Processing ^STOXX50E (EQUITY) from yfinance...\n",
            "  ✓ Inserted 4004 rows\n",
            "Processing IVW (EQUITY) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing IVE (EQUITY) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing XLU (EQUITY) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing XLF (EQUITY) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing DGS1 (RATES) from fred...\n",
            "  ✓ Inserted 4161 rows\n",
            "Processing DGS2 (RATES) from fred...\n",
            "  ✓ Inserted 4161 rows\n",
            "Processing DGS5 (RATES) from fred...\n",
            "  ✓ Inserted 4161 rows\n",
            "Processing DGS10 (RATES) from fred...\n",
            "  ✓ Inserted 4161 rows\n",
            "Processing DGS30 (RATES) from fred...\n",
            "  ✓ Inserted 4161 rows\n",
            "Processing T10Y2Y (RATES) from fred...\n",
            "  ✓ Inserted 4162 rows\n",
            "Processing FEDFUNDS (RATES) from fred...\n",
            "  ✓ Inserted 191 rows\n",
            "Processing SOFR (RATES) from fred...\n",
            "  ✓ Inserted 2009 rows\n",
            "Processing T5YIE (RATES) from fred...\n",
            "  ✓ Inserted 4162 rows\n",
            "Processing T10YIE (RATES) from fred...\n",
            "  ✓ Inserted 4162 rows\n",
            "Processing DFII10 (RATES) from fred...\n",
            "  ✓ Inserted 4161 rows\n",
            "Processing DX-Y.NYB (FX) from yfinance...\n",
            "  ✓ Inserted 4014 rows\n",
            "Processing EURUSD=X (FX) from yfinance...\n",
            "  ✓ Inserted 4155 rows\n",
            "Processing GBPUSD=X (FX) from yfinance...\n",
            "  ✓ Inserted 4155 rows\n",
            "Processing USDJPY=X (FX) from yfinance...\n",
            "  ✓ Inserted 4155 rows\n",
            "Processing AUDUSD=X (FX) from yfinance...\n",
            "  ✓ Inserted 4154 rows\n",
            "Processing USDCNY=X (FX) from yfinance...\n",
            "  ✓ Inserted 4153 rows\n",
            "Processing BAMLH0A0HYM2 (CREDIT) from fred...\n",
            "  ✓ Inserted 4215 rows\n",
            "Processing BAMLC0A0CM (CREDIT) from fred...\n",
            "  ✓ Inserted 4215 rows\n",
            "Processing T10Y3M (CREDIT) from fred...\n",
            "  ✓ Inserted 4162 rows\n",
            "Processing TEDRATE (CREDIT) from fred...\n",
            "  ✓ Inserted 3146 rows\n",
            "Processing GC=F (COMMODITIES) from yfinance...\n",
            "  ✓ Inserted 4012 rows\n",
            "Processing SI=F (COMMODITIES) from yfinance...\n",
            "  ✓ Inserted 4012 rows\n",
            "Processing CL=F (COMMODITIES) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing BZ=F (COMMODITIES) from yfinance...\n",
            "  ✓ Inserted 3982 rows\n",
            "Processing NG=F (COMMODITIES) from yfinance...\n",
            "  ✓ Inserted 4014 rows\n",
            "Processing HG=F (COMMODITIES) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing BTC-USD (COMMODITIES) from yfinance...\n",
            "  ✓ Inserted 4108 rows\n",
            "Processing ^VIX (VOL) from yfinance...\n",
            "  ✓ Inserted 4013 rows\n",
            "Processing ^VVIX (VOL) from yfinance...\n",
            "  ✓ Inserted 4004 rows\n",
            "Processing ^MOVE (VOL) from yfinance...\n",
            "  ✓ Inserted 3930 rows\n",
            "Processing UNRATE (MACRO) from fred...\n",
            "  ✓ Inserted 189 rows\n",
            "Processing CPIAUCSL (MACRO) from fred...\n",
            "  ✓ Inserted 189 rows\n",
            "Processing PCEPI (MACRO) from fred...\n",
            "  ✓ Inserted 189 rows\n",
            "Processing GDP (MACRO) from fred...\n",
            "  ✓ Inserted 62 rows\n",
            "Processing UMCSENT (MACRO) from fred...\n",
            "  ✓ Inserted 190 rows\n",
            "Processing DCOILWTICO (MACRO) from fred...\n",
            "  ✓ Inserted 4157 rows\n",
            "Processing M2SL (MACRO) from fred...\n",
            "  ✓ Inserted 190 rows\n",
            "Processing USSLIND (MACRO) from fred...\n",
            "  ✓ Inserted 122 rows\n",
            "Processing NFCI (MACRO) from fred...\n",
            "  ✓ Inserted 832 rows\n",
            "Processing WALCL (MACRO) from fred...\n",
            "  ✓ Inserted 832 rows\n",
            "\n",
            "Ingestion complete! Success: 54, Failed: 0\n"
          ]
        }
      ],
      "source": [
        "ticker_filter = ['ISMMFG']\n",
        "start_date='2010-01-01'\n",
        "\n",
        "ingest_all(\n",
        "        start_date=start_date,\n",
        "        ticker_filter=None,\n",
        "        dry_run=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c087cd78",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
